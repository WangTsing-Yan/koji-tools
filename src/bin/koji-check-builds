#!/usr/bin/python

import Queue
import logging
import optparse
import os
import threading
import time

import dateutil
import koji as _koji  # koji declared using profile module in main()
from koji.util import md5_constructor
import rpm


logger = logging.getLogger('koji.checkbuilds')

# an event to indicate that the feeder thread is done
feeder_done = threading.Event()

# queue to hold actions in the pipeline
queue = Queue.Queue()


def main():
    global koji
    parser = optparse.OptionParser(usage='%prog [options]')
    parser.add_option('-p', '--profile', default='BOGUS',
                      help='pick a profile')
    # ^ XXX fix default later
    parser.add_option('-j', '--threads', default=5, type='int',
                      help='worker thread count')
    # verbosity options
    parser.add_option("-d", "--debug", action="store_true",
                      help="show debug output")
    parser.add_option("-v", "--verbose", action="store_true",
                      help="show verbose output")
    parser.add_option("-q", "--quiet", action="store_true", default=False,
                      help="run quietly")
    # build selection options
    parser.add_option("--package", help="List builds for this package")
    parser.add_option("--buildid", help="List specific build from ID or nvr")
    parser.add_option("--before",
                      help="List builds built before this time")
    parser.add_option("--after",
                      help="List builds built after this time")
    parser.add_option("--type", help="List builds of this type.")
    parser.add_option("--prefix", help="Only list packages starting with this prefix")
    parser.add_option("--owner", help="List builds built by this owner")
    parser.add_option("--volume", help="List builds by volume ID")

    opts, args = parser.parse_args()

    if args:
        parser.error('This command takes no arguments. See --help for options')

    koji = _koji.get_profile_module(opts.profile)

    logging.basicConfig()
    if opts.debug:
        logger.setLevel(logging.DEBUG)
    elif opts.quiet:
        logger.setLevel(logging.ERROR)
    else:
        logger.setLevel(logging.WARN)

    # start our threads
    fthread = threading.Thread(name='feeder', target=feeder_thread,
                               args=(opts, args))
    fthread.setDaemon(True)
    fthread.start()

    threads = []
    for i in range(opts.threads):
        wthread = threading.Thread(name='worker %i' % i, target=worker_thread,
                                   args=(opts,))
        wthread.setDaemon(True)
        wthread.start()
        threads.append(wthread)

    # the builds thread will be the first to finish
    fthread.join()
    feeder_done.set()

    # now we wait for the queue to be empty
    queue.join()

    print('Finished. Waiting for workers to stop.')
    for wthread in threads:
        wthread.join()


sessions = threading.local()


def get_session():
    '''Get session for this thread, create if needed'''
    try:
        return sessions.session
    except AttributeError:
        sessions.session = _get_session()
        return sessions.session


def _get_session():
    '''Get a new anonymous session'''
    session_opts = koji.grab_session_options(koji.config)
    session_opts['anon_retry'] = True
    return koji.ClientSession(koji.config.server, session_opts)


def feeder_thread(opts, args):
    '''Fetch builds and feed them into the queu'''
    for build in get_builds(opts, args):
        while queue.qsize() > 1000:
            # avoid overloading the queue
            logger.debug('queue is large')
            time.sleep(5)
        checker = BuildChecker(build)
        queue.put([checker.check, {}])
        logger.debug("queueing build %(nvr)s", build)


def get_builds(options, args):
    '''Yield all requested builds'''
    session = get_session()
    chunksize = 10000
    opts = {}
    opts['queryOpts'] = {'order': 'build.id', 'offset': 0, 'limit': chunksize}
    for key in ('type', 'prefix'):
        value = getattr(options, key)
        if value is not None:
            opts[key] = value
    if options.package:
        try:
            opts['packageID'] = int(options.package)
        except ValueError:
            package = session.getPackageID(options.package)
            if package is None:
                raise ValueError('invalid package option')
            opts['packageID'] = package
    if options.owner:
        try:
            opts['userID'] = int(options.owner)
        except ValueError:
            user = session.getUser(options.owner)
            if user is None:
                raise ValueError("Invalid owner option")
            opts['userID'] = user['id']
    if options.volume:
        try:
            opts['volumeID'] = int(options.volume)
        except ValueError:
            volumes = session.listVolumes()
            volumeID = None
            for volume in volumes:
                if options.volume == volume['name']:
                    volumeID = volume['id']
            if volumeID is None:
                raise ValueError("Invalid volume option")
            opts['volumeID'] = volumeID
    for opt in ('before', 'after'):
        val = getattr(options, opt)
        if not val:
            continue
        try:
            ts = float(val)
            setattr(options, opt, ts)
            continue
        except ValueError:
            pass
        try:
            dt = dateutil.parser.parse(val)
            ts = time.mktime(dt.timetuple())
            setattr(options, opt, ts)
        except:
            raise ValueError("Invalid time specification: %s" % val)
    if options.before:
        opts['completeBefore'] = getattr(options, 'before')
    if options.after:
        opts['completeAfter'] = getattr(options, 'after')

    while True:
        logger.debug("chunk")
        chunk = session.listBuilds(**opts)
        logger.debug("got chunk")
        if not chunk:
            break
        opts['queryOpts']['offset'] += chunksize
        for build in chunk:
            yield build


def worker_thread(opts):
    '''Handle tasks in queue'''
    while True:
        try:
            func, kwargs = queue.get(block=True, timeout=5)
        except Queue.Empty:
            if feeder_done.is_set():
                # is this enough?
                break
            continue
        func(**kwargs)
        queue.task_done()


class BuildChecker(object):

    def __init__(self, build):
        self.build = build

    def check(self):
        '''Initial build check, plus queue deeper checks'''
        build = self.build
        state = koji.BUILD_STATES[build['state']]
        self.build_dir = koji.pathinfo.build(build)
        if state == 'BUILDING':
            # ignore these
            return
        elif state in ('FAILED', 'DELETED', 'CANCELED'):
            if not os.path.isdir(self.build_dir):
                logger.warn('Stray build directory: %s (build is %s)',
                             self.build_dir, state)
            # don't check further for these
            return
        elif state == 'COMPLETE':
            if not os.path.isdir(self.build_dir):
                logger.warn('Build directory missing: %s', self.build_dir)
                return
        else:
            # should not happen
            raise ValueError('Build state is %s' % state)
        queue.put([self.check_files, {}])

    def check_files(self):
        self.check_rpms()
        self.check_archives()
        # TODO: other files?

    def get_rpms(self):
        '''Get rpms to check'''
        session = get_session()
        rpms = []
        for rpminfo in session.listRPMs(buildID=self.build['build_id']):
            fn = '%s/%s' % (self.build_dir, koji.pathinfo.rpm(rpminfo))
            rpminfo['_fn'] = fn
            if rpminfo['metadata_only']:
                # TODO verify file not present
                logger.debug('Skipping metadata-only rpm: %s', fn)
                continue
            rpms.append(rpminfo)
        self.rpms = rpms
        return rpms

    def check_rpms(self):
        self.get_rpms()
        for rpminfo in self.rpms:
            fn = rpminfo['_fn']
            try:
                st = os.stat(fn)
            except OSError as ex:
                if ex.errno == 2:
                    logger.warn('Missing rpm: %s', fn)
                    continue
                raise
            if st.st_size != rpminfo['size']:
                logger.warn('Wrong size for: %s', fn)
                logger.warn('  db: %i, file: %i', rpminfo['size'], st.st_size)
            try:
                hdr = koji.get_rpm_header(fn)
                # ^NOTE: this call does not *verify*
            except Exception:
                logger.warn('Unable to read header for: %s', fn)
                continue
            sigmd5 = koji.hex_string(hdr[rpm.RPMTAG_SIGMD5])
            if rpminfo['payloadhash'] != sigmd5:
                logger.warn('Wrong sigmd5 for: %s', fn)
                logger.warn('  db: %s, file: %s', rpminfo['payloadhash'], sigmd5)
            # TODO actually verify the rpm
        self.check_rpm_sigs()
        # ^ separate task?

    def check_rpm_sigs(self):
        '''Validate signature data on disc'''
        build = self.build
        session = get_session()
        sig_idx = {}
        session.multicall = True
        for rpminfo in self.rpms:
            session.queryRPMSigs(rpm_id=rpminfo['id'])
        for rpminfo, [sigs] in zip(self.rpms, session.multiCall(strict=True)):
            sigs = session.queryRPMSigs(rpm_id=rpminfo['id'])
            for sig in sigs:
                sig_idx.setdefault(sig['sigkey'], []).append([rpminfo, sig])
        logger.debug('Keys for %s: %s', build['nvr'], sig_idx.keys())
        for sigkey in sig_idx:
            cachedir = os.path.join(self.build_dir, 'data/sigcache/%s' % sigkey)
            if not os.path.isdir(cachedir):
                logger.warning("Signature cache dir missing: %s", cachedir)
                continue
            # else
            for rpminfo, sig in sig_idx[sigkey]:
                cachefile = os.path.join(self.build_dir, koji.pathinfo.sighdr(rpminfo, sigkey))
                if not os.path.isfile(cachefile):
                    logger.warn("Cached signature missing: %s", cachefile)
                    continue
                sighash = md5_constructor(file(cachefile).read()).hexdigest()
                if sighash != sig['sighash']:
                    logger.warn('Cached signature mismatch for %s\n'
                            '  db: %s, file:%s',
                            cachefile, sig['sighash'], sighash)
        for sigkey in sig_idx:
            signeddir = os.path.join(self.build_dir, 'data/signed/%s' % sigkey)
            if not os.path.isdir(signeddir):
                # ok - signed copies are temporary
                continue
            for rpminfo, sig in sig_idx[sigkey]:
                signed = os.path.join(self.build_dir, koji.pathinfo.signed(rpminfo, sigkey))
                if not os.path.exists(signed):
                    # still ok
                    continue
                # check that sig header is matches
                hdr = koji.rip_rpm_sighdr(signed)
                sighash = md5_constructor(hdr).hexdigest()
                if sighash != sig['sighash']:
                    logger.warn('Signed copy sighdr mismatch: %s\n'
                            '  db: %s, file: %s',
                            signed, sig['sighash'], sighash)
                # TODO: verify signed copy

    def check_archives(self):
        build = self.build
        session = get_session()
        # first gather archives
        archives = {}
        for legacy in ['maven', 'win', 'image']:
            for archive in session.listArchives(buildID=build['build_id'], type=legacy):
                archives.setdefault(archive['id'], archive)
        for archive in session.listArchives(buildID=build['build_id']):
            archives.setdefault(archive['id'], archive)

        for archive in archives.values():
            if archive['btype'] == 'maven':
                fn = '%s/%s' % (koji.pathinfo.mavenbuild(build),
                        koji.pathinfo.mavenfile(archive))
            elif archive['btype'] == 'win':
                fn = '%s/%s' % (koji.pathinfo.winbuild(build),
                        koji.pathinfo.winfile(archive))
            elif archive['btype'] == 'image':
                fn = '%s/%s' % (koji.pathinfo.imagebuild(build),
                        archive['filename'])
            else:
                fn = '%s/%s' % (koji.pathinfo.typedir(build, archive['btype']),
                        archive['filename'])
            if archive['metadata_only']:
                # TODO verify file not present
                logger.debug('Skipping metadata-only archive: %s', fn)
                continue
            try:
                st = os.stat(fn)
            except OSError as ex:
                if ex.errno == 2:
                    logger.warn('Missing archive: %s', fn)
                    continue
                raise
            if st.st_size != archive['size']:
                logger.warn('Wrong size for: %s', fn)
                logger.warn('  db: %i, file: %i', archive['size'], st.st_size)
        # TODO verify checksum


if __name__ == '__main__':
    main()
